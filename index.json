[{"authors":null,"categories":null,"content":"I am a Machine Learning Scientist at the Amazon Development Centre based in London, UK, working on advancing AI technologies for Alexa.\nBefore joining Amazon, I was a postdoctoral research scientist at the University of Oxford based in the Wellcome Centre for Human Genetics and the Department of Statistics. Before Oxford, I received my PhD from MINES ParisTech, Paris, France, under the supervision of Jean-Philippe Vert, and I was a Marie Curie Initial Training Network fellow in Machine Learning for Personalized Medicine.\n  Download my resume.\n","date":1650844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1650844800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://YunlongJiao.github.io/author/yunlong-jiao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yunlong-jiao/","section":"authors","summary":"I am a Machine Learning Scientist at the Amazon Development Centre based in London, UK, working on advancing AI technologies for Alexa.\nBefore joining Amazon, I was a postdoctoral research scientist at the University of Oxford based in the Wellcome Centre for Human Genetics and the Department of Statistics.","tags":null,"title":"Yunlong Jiao","type":"authors"},{"authors":["Fangyu Liu","Yunlong Jiao","Jordan Massiah","Emine Yilmaz","Serhii Havrylov"],"categories":null,"content":"","date":1650844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650844800,"objectID":"f4a31d56bd22e506ddc31d997d35400e","permalink":"https://YunlongJiao.github.io/publication/liu2022trans/","publishdate":"2022-01-24T00:00:00Z","relpermalink":"/publication/liu2022trans/","section":"publication","summary":"Bootstrapping an unsupervised sentence encoder by self-distilling knowledge between its bi-encoder and cross-encoder forms, enhancing each other iteratively.","tags":["Deep Learning","Self-Supervised Learning","Natural Language Processing"],"title":"Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations","type":"publication"},{"authors":["Arushi Goel","Yunlong Jiao","Jordan Massiah"],"categories":null,"content":"","date":1643155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643155200,"objectID":"3c90675e60974fb45e03f6f146907734","permalink":"https://YunlongJiao.github.io/publication/goel2022pars/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/publication/goel2022pars/","section":"publication","summary":"We propose a novel pseudo-label aware robust sample selection method for learning with noisy labels that outperforms state-of-the-art especially in presence of high label noise.","tags":["Deep Learning","Computer Vision","Learning with Noisy Labels"],"title":"PARS: Pseudo-Label Aware Robust Sample Selection for Learning with Noisy Labels","type":"publication"},{"authors":["Giorgio Giannone","Serhii Havrylov","Jordan Massiah","Emine Yilmaz","Yunlong Jiao"],"categories":null,"content":"","date":1639353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639353600,"objectID":"1567dd4a939a803571f239a45b8cfd9d","permalink":"https://YunlongJiao.github.io/publication/giannone2021just/","publishdate":"2021-11-30T00:00:00Z","relpermalink":"/publication/giannone2021just/","section":"publication","summary":"Recent work has unveiled how average generalization frequently relies on superficial patterns in data. The consequences are brittle models with poor performance in the presence of domain shift in group distribution at test time. When the subgroups in the training data are known, we can use tools from robust optimization to tackle the problem. However, group annotation and identification are time-consuming tasks, especially on large datasets. A recent line of research~\\cite{liu2021just} is trying to solve this problem with implicit group distribution at training time, leveraging self-supervision and oversampling to improve generalization on minority groups. Following such ideas, we propose a new class-conditional variant of MixUp~\\cite{zhang2017mixup} for worst-group generalization, augmenting the training distribution with a continuous distribution of groups. Our method, called Just Mix Once (JM1), is domain-agnostic, computationally efficient, and performs on par or better than the state-of-the-art on worst-group generalization.","tags":["Deep Learning","Distribution Shift"],"title":"Just Mix Once: Mixing Samples with Implicit Group Distribution","type":"publication"},{"authors":["Adam Gabrys","Yunlong Jiao","Viacheslav Klimkov","Daniel Korzekwa","Roberto Barra-Chicote"],"categories":null,"content":"","date":1630281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630281600,"objectID":"d9f25ee76c3a613991f65d86ac180919","permalink":"https://YunlongJiao.github.io/publication/gabrys2021improving/","publishdate":"2021-08-30T00:00:00Z","relpermalink":"/publication/gabrys2021improving/","section":"publication","summary":"This paper proposes a general enhancement to the Normalizing Flows (NF) used in neural vocoding. As a case study, we improve expressive speech vocoding with a revamped Parallel Wavenet (PW). Specifically, we propose to extend the affine transformation of PW to the more expressive invertible non-affine function. The greater expressiveness of the improved PW leads to better-perceived signal quality and naturalness in the waveform reconstruction and text-to-speech (TTS) tasks. We evaluate the model across different speaking styles on a multi-speaker, multi-lingual dataset. In the waveform reconstruction task, the proposed model closes the naturalness and signal quality gap from the original PW to recordings by 10%, and from other state-of-the-art neural vocoding systems by more than 60%. We also demonstrate improvements in objective metrics on the evaluation test set with L2 Spectral Distance and Cross-Entropy reduced by 3% and 6‰ comparing to the affine PW. Furthermore, we extend the probability density distillation procedure proposed by the original PW paper, so that it works with any non-affine invertible and differentiable function.","tags":["Deep Learning","Text-to-Speech"],"title":"Improving the expressiveness of neural vocoding with non-affine Normalizing Flows","type":"publication"},{"authors":["Yunlong Jiao","Adam Gabrys","Georgi Tinchev","Bartosz Putrycz","Daniel Korzekwa","Viacheslav Klimkov"],"categories":null,"content":"","date":1620864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620864000,"objectID":"db1f49313a1aa52dac6fc56ca65ead27","permalink":"https://YunlongJiao.github.io/publication/jiao2021universal/","publishdate":"2021-05-13T00:00:00Z","relpermalink":"/publication/jiao2021universal/","section":"publication","summary":"We present a universal neural vocoder based on Parallel WaveNet, with an additional conditioning network called Audio Encoder. Our universal vocoder offers real-time high-quality speech synthesis on a wide range of use cases. We tested it on 43 internal speakers of diverse age and gender, speaking 20 languages in 17 unique styles, of which 7 voices and 5 styles were not exposed during training. We show that the proposed universal vocoder significantly outperforms speaker-dependent vocoders overall. We also show that the proposed vocoder outperforms several existing neural vocoder architectures in terms of naturalness and universality. These findings are consistent when we further test on more than 300 open-source voices.","tags":["Deep Learning","Text-to-Speech"],"title":"Universal Neural Vocoding with Parallel WaveNet","type":"publication"},{"authors":["Fabian Heinemann","Stefan Kobel","Sven Dahlmanns","Jean-Philippe Vert","Yunlong Jiao"],"categories":null,"content":"Patent application filed by Roche Diagnostics GmbH, F. Hoffmann-La Roche AG.\n","date":1576800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576800000,"objectID":"784e12c425bccd7668a0f9c7df7650bc","permalink":"https://YunlongJiao.github.io/publication/jiao2019failure/","publishdate":"2019-12-20T00:00:00Z","relpermalink":"/publication/jiao2019failure/","section":"publication","summary":"A method for predicting a failure state of an automated analyzer for analyzing a biological sample is disclosed. The method includes obtaining a prediction algorithm for predicting a failure state of an automated analyzer. The prediction algorithm is configured to predict a failure state of the automated analyzer based on calibration data and/or quality control data generated by an automated analyzer. The method also includes obtaining calibration data and/or quality control data of the automated analyzer and processing the calibration data and/or quality control data by using the prediction algorithm to predict a failure state of the automated analyzer.","tags":["Machine Learning","Information Retrieval"],"title":"Failure State Prediction for Automated Analyzers for Analyzing a Biological Sample","type":"publication"},{"authors":["Jean-Philippe Vert (Prof.)","Yunlong Jiao (T.A.)"],"categories":null,"content":"Master course at African Master’s in Machine Intelligence (AMMI).\nThis course covers basic concepts in machine learning in high dimension, and the importance of regularization. We study in detail high-dimensional linear models regularized by the Euclidean norm, including ridge regression, ridge logistic regression and support vector machines. We then show how positive definite kernels allows to transform these linear models into rich nonlinear models, usable even for non-vectorial data such as strings and graphs, and convenient for integrating heterogeneous data.\nInstructors:\n Jean-Philippe Vert (Prof.) Yunlong Jiao (T.A.)  More on the course website.\n","date":1548028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548028800,"objectID":"543f9fb4972c061b54115cebfeb1575b","permalink":"https://YunlongJiao.github.io/teaching/2019ammi/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/teaching/2019ammi/","section":"teaching","summary":"Master course at [African Master’s in Machine Intelligence (AMMI)](https://aimsammi.org/).","tags":["Machine Learning"],"title":"Spring 2019: Kernel Methods in Machine Learning","type":"teaching"},{"authors":["Yunlong Jiao","Jean-Philippe Vert"],"categories":null,"content":"","date":1530748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530748800,"objectID":"0f9923f24aab605950427bd3bd021af7","permalink":"https://YunlongJiao.github.io/publication/jiao2018weighted/","publishdate":"2018-07-05T00:00:00Z","relpermalink":"/publication/jiao2018weighted/","section":"publication","summary":"We propose new positive definite kernels for permutations. First we introduce a weighted version of the Kendall kernel, which allows to weight unequally the contributions of different item pairs in the permutations depending on their ranks. Like the Kendall kernel, we show that the weighted version is invariant to relabeling of items and can be computed efficiently in $O(n \\\\ln(n))$ operations, where $n$ is the number of items in the permutation. Second, we propose a supervised approach to learn the weights by jointly optimizing them with the function estimated by a kernel machine. Third, while the Kendall kernel considers pairwise comparison between items, we extend it by considering higher-order comparisons among tuples of items and show that the supervised approach of learning the weights can be systematically generalized to higher-order permutation kernels.","tags":["Machine Learning","Kernel Methods"],"title":"The Weighted Kendall and High-order Kernels for Permutations","type":"publication"},{"authors":["Yunlong Jiao","Jean-Philippe Vert"],"categories":null,"content":"","date":1530316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530316800,"objectID":"03148a224edff158abb9c88c1d98608e","permalink":"https://YunlongJiao.github.io/publication/jiao2018kendall/","publishdate":"2018-06-30T00:00:00Z","relpermalink":"/publication/jiao2018kendall/","section":"publication","summary":"We show that the widely used Kendall tau correlation coefficient, and the related Mallows kernel, are positive definite kernels for permutations. They offer computationally attractive alternatives to more complex kernels on the symmetric group to learn from rankings, or learn to rank. We show how to extend these kernels to partial rankings, multivariate rankings and uncertain rankings. Examples are presented on how to formulate typical problems of learning from rankings such that they can be solved with state-of-the-art kernel algorithms. We demonstrate promising results on clustering heterogeneous rank data and high-dimensional classification problems in biomedical applications.","tags":["Machine Learning","Kernel Methods"],"title":"The Kendall and Mallows Kernels for Permutations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1511136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511136000,"objectID":"ce0f21bdb4f7d5305e6a28790e5093f1","permalink":"https://YunlongJiao.github.io/software/kernrank/","publishdate":"2017-11-20T00:00:00Z","relpermalink":"/software/kernrank/","section":"software","summary":"`R` package implementing kernel functions and methods for rank data","tags":["Machine Learning","Kernel Methods"],"title":"kernrank","type":"software"},{"authors":null,"categories":null,"content":"","date":1511136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511136000,"objectID":"00576082399e5237545044d2490ab487","permalink":"https://YunlongJiao.github.io/software/kmr/","publishdate":"2017-11-20T00:00:00Z","relpermalink":"/software/kmr/","section":"software","summary":"A kernel multitask regression algorithm implemented in `R`","tags":["Machine Learning","Kernel Methods"],"title":"kmr","type":"software"},{"authors":["Yunlong Jiao","Jean-Philippe Vert"],"categories":null,"content":"","date":1511136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511136000,"objectID":"9ebe537b72d84af9d6f29537f30687d9","permalink":"https://YunlongJiao.github.io/publication/jiao2017network/","publishdate":"2017-11-20T00:00:00Z","relpermalink":"/publication/jiao2017network/","section":"publication","summary":"Biological networks are a common way of describing information on relationships between genes that are accumulated from many years of biomedical research, and they are thus potentially valuable when incorporated as prior knowledge to guide biomarker discovery in genomic data analysis. In this study, we focus on network-based regularization methods through a predictive framework with linear models, and propose to use a class of methods based on wavelet smoothing over undirected graphs that directly detect subnetworks composing of collaboratively functional gene modules. We perform breast cancer survival analysis using a large gene expression dataset and a protein-protein interaction network obtained from a public database, and demonstrate that the proposed methods are able to improve gene selection in terms of stability, connectivity and interpretability while achieving competitive performance of survival risk prediction. Our results also serve a comparative study benchmarking several network-free and network-based regularization methods for gene selection related to breast cancer survival.","tags":["Signal Processing","Computational Biology"],"title":"Network-based Wavelet Smoothing for Analysis of Genomic Data","type":"publication"},{"authors":["Yunlong Jiao","Marta R Hidalgo","Cankut Cubuk","Alicia Amadoz","Jose Carbonell-Caballero","Jean-Philippe Vert","Joaquin Dopazo"],"categories":null,"content":"","date":1510272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510272000,"objectID":"4e1404f7a47710acf3abe50f9aa79b89","permalink":"https://YunlongJiao.github.io/publication/jiao2017signaling/","publishdate":"2017-11-10T00:00:00Z","relpermalink":"/publication/jiao2017signaling/","section":"publication","summary":"With the advent of high-throughput technologies for genome-wide expression profiling, a large number of methods have been proposed to discover gene-based signatures as biomarkers to guide cancer prognosis. However, it is often difficult to interpret the list of genes in a prognostic signature regarding the underlying biological processes responsible for disease progression or therapeutic response. A particularly interesting alternative to gene-based biomarkers is mechanistic biomarkers, derived from signaling pathway activities, which are known to play a key role in cancer progression and thus provide more informative insights into cellular functions involved in cancer mechanism. In this study, we demonstrate that pathway-level features, such as the activity of signaling circuits, outperform conventional gene-level features in prediction performance in breast cancer prognosis. We also show that the proposed classification scheme can even suggest, in addition to relevant signaling circuits related to disease outcome, a list of genes that do not code for signaling proteins whose contribution to cancer prognosis potentially supplements the mechanisms detected by pathway analysis.","tags":["Computational Biology"],"title":"Signaling Pathway Activities Improve Prognosis for Breast Cancer","type":"publication"},{"authors":["Elsa Bernard","Yunlong Jiao","Erwan Scornet","Veronique Stoven","Thomas Walter","Jean-Philippe Vert"],"categories":null,"content":"","date":1506384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506384000,"objectID":"2a563e39e17027a492241037c9b501b7","permalink":"https://YunlongJiao.github.io/publication/bernard2017kernel/","publishdate":"2017-09-26T00:00:00Z","relpermalink":"/publication/bernard2017kernel/","section":"publication","summary":"The development of high-throughput *in vitro* assays to study quantitatively the toxicity of chemical compounds on genetically characterized human-derived cell lines paves the way to *predictive toxicogenetics*, where one would be able to predict the toxicity of any particular compound on any particular individual. In this paper we present a machine learning-based approach for that purpose, kernel multitask regression (KMR), which combines chemical characterizations of molecular compounds with genetic and transcriptomic characterizations of cell lines to predict the toxicity of a given compound on a given cell line. We demonstrate the relevance of the method on the recent DREAM8 Toxicogenetics challenge, where it ranked among the best state-of-the-art models, and discuss the importance of choosing good descriptors for cell lines and chemicals.","tags":["Machine Learning","Kernel Methods","Computational Biology"],"title":"Kernel Multitask Regression for Toxicogenetics","type":"publication"},{"authors":["Yunlong Jiao"],"categories":null,"content":"","date":1505088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505088000,"objectID":"f7b5fc3e8ede9addc4b54f987009b50e","permalink":"https://YunlongJiao.github.io/publication/jiao2017rank/","publishdate":"2017-09-11T00:00:00Z","relpermalink":"/publication/jiao2017rank/","section":"publication","summary":"Breast cancer is the second most common cancer worldwide and the leading cause of women’s death from cancer. Improving cancer prognosis has been one of the problems of primary interest towards better clinical management and treatment decision making for cancer patients. With the rapid advancement of genomic profiling technologies in the past decades, easy availability of a substantial amount of genomic data for medical research has been motivating the currently popular trend of using computational tools, especially machine learning in the era of data science, to discover molecular biomarkers regarding prognosis improvement. This thesis is conceived following two lines of approaches intended to address two major challenges arising in genomic data analysis for breast cancer prognosis from a methodological standpoint of machine learning: rank-based approaches for improved molecular prognosis and network-guided approaches for enhanced biomarker discovery. Furthermore, the methodologies developed and investigated in this thesis, pertaining respectively to learning with rank data and learning on graphs, have a significant contribution to several branches of machine learning, concerning applications across but not limited to cancer biology and social choice theory.","tags":["Machine Learning","Computational Biology"],"title":"Rank-based Molecular Prognosis and Network-guided Biomarker Discovery for Breast Cancer","type":"publication"},{"authors":["Yunlong Jiao","Anna Korba","Eric Sibony"],"categories":null,"content":"","date":1466380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466380800,"objectID":"33e27cff741c583ed27fa7f755f4000e","permalink":"https://YunlongJiao.github.io/publication/jiao2016controlling/","publishdate":"2016-06-20T00:00:00Z","relpermalink":"/publication/jiao2016controlling/","section":"publication","summary":"Due to its numerous applications, rank aggregation has become a problem of major interest across many fields of the computer science literature. In the vast majority of situations, Kemeny consensus(es) are considered as the ideal solutions. It is however well known that their computation is NP-hard. Many contributions have thus established various results to apprehend this complexity. In this paper we introduce a practical method to predict, for a ranking and a dataset, how close the Kemeny consensus(es) are to this ranking. A major strength of this method is its generality: it does not require any assumption on the dataset nor the ranking. Furthermore, it relies on a new geometric interpretation of Kemeny aggregation that, we believe, could lead to many other results.","tags":["Machine Learning","Information Retrieval"],"title":"Controlling the distance to a Kemeny consensus without computing it","type":"publication"},{"authors":["Federica Eduati","Lara M Mangravite","Tao Wang","Hao Tang","J Christopher Bare","Ruili Huang","Thea Norman","Mike Kellen","Michael P Menden","Jichen Yang","Xiaowei Zhan","Rui Zhong","Guanghua Xiao","Menghang Xia","Nour Abdo","Oksana Kosyk","The NIEHS-NCATS-UNC DREAM Toxicogenetics Collaboration","et al."],"categories":null,"content":"","date":1439164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1439164800,"objectID":"ec03d2b1a1bbb32c003909bdf1904a1d","permalink":"https://YunlongJiao.github.io/publication/eduati2015prediction/","publishdate":"2015-08-10T00:00:00Z","relpermalink":"/publication/eduati2015prediction/","section":"publication","summary":"The ability to computationally predict the effects of toxic compounds on humans could help address the deficiencies of current chemical safety testing. Here, we report the results from a community-based DREAM challenge to predict toxicities of environmental compounds with potential adverse health effects for human populations. We measured the cytotoxicity of 156 compounds in 884 lymphoblastoid cell lines for which genotype and transcriptional data are available as part of the Tox21 1000 Genomes Project. The challenge participants developed algorithms to predict interindividual variability of toxic response from genomic profiles and population-level cytotoxicity data from structural attributes of the compounds. 179 submitted predictions were evaluated against an experimental data set to which participants were blinded. Individual cytotoxicity predictions were better than random, with modest correlations (Pearson's $r ","tags":["Computational Biology"],"title":"Prediction of human population responses to toxic compounds by a collaborative competition","type":"publication"},{"authors":["Yunlong Jiao","Jean-Philippe Vert"],"categories":null,"content":"","date":1436227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436227200,"objectID":"af49894de437fbae2645b8d987531ea4","permalink":"https://YunlongJiao.github.io/publication/jiao2015kendall/","publishdate":"2015-07-07T00:00:00Z","relpermalink":"/publication/jiao2015kendall/","section":"publication","summary":"We show that the widely used Kendall tau correlation coefficient is a positive definite kernel for permutations. It offers a computationally attractive alternative to more complex kernels on the symmetric group to learn from rankings, or to learn to rank. We show how to extend it to partial rankings or rankings with uncertainty, and demonstrate promising results on high-dimensional classification problems in biomedical applications.","tags":["Machine Learning","Kernel Methods"],"title":"The Kendall and Mallows Kernels for Permutations","type":"publication"}]